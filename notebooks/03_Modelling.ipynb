{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Training\n",
    "\n",
    "In this section, we will:\n",
    "1. Load the training data (`x_train_woe.csv` and `y_train_proxy.csv`).\n",
    "2. Standardize the features.\n",
    "3. Train a Logistic Regression model.\n",
    "4. Tune hyperparameters using Grid Search.\n",
    "5. Evaluate the model's performance.\n",
    "\n",
    "Let's begin by loading the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We load the WoE-transformed features (`x_train_woe.csv`) and the target labels (`y_train_proxy.csv`).\n",
    "The target variable (`y_train_proxy`) is assumed to be in the `Label` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_Hour_woe  Transaction_Day_woe  Recency_woe  Stability_woe  \\\n",
      "0              0.543092             0.467015     1.751994            0.0   \n",
      "1              1.123482             0.467015     1.751994            0.0   \n",
      "2             -0.700449            -0.222864     1.751994            0.0   \n",
      "3             -0.700449             0.147976     1.751994            0.0   \n",
      "4              0.543092             0.467015     1.751994            0.0   \n",
      "\n",
      "   Monetary_woe  Frequency_woe  Transaction_Month_woe  Transaction_Year_woe  \\\n",
      "0      1.771599       1.816266                    0.0                   0.0   \n",
      "1      1.771599       1.816266                    0.0                   0.0   \n",
      "2      1.771599       1.816266                    0.0                   0.0   \n",
      "3      1.771599       1.816266                    0.0                   0.0   \n",
      "4      1.771599       1.816266                    0.0                   0.0   \n",
      "\n",
      "   AvgTransactionInterval_woe  \n",
      "0                    0.599176  \n",
      "1                   -0.096863  \n",
      "2                   -0.096863  \n",
      "3                   -0.096863  \n",
      "4                    0.599176  \n"
     ]
    }
   ],
   "source": [
    "# Load the WoE-transformed data and labels\n",
    "x_train = pd.read_csv('../data/processed/x_train_woe.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train_proxy.csv')['Label']\n",
    "\n",
    "# Preview the data\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "We will standardize the features using `StandardScaler` to make sure the features have a mean of 0 and standard deviation of 1. This is particularly important for Logistic Regression as it is sensitive to the scale of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Logistic Regression Model\n",
    "\n",
    "We will initialize and train the Logistic Regression model on the standardized training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Balanced Class Weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      3574\n",
      "           1       0.02      1.00      0.03         8\n",
      "\n",
      "    accuracy                           0.87      3582\n",
      "   macro avg       0.51      0.94      0.48      3582\n",
      "weighted avg       1.00      0.87      0.93      3582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression with balanced class weights\n",
    "log_reg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_train_pred = log_reg.predict(x_train_scaled)\n",
    "print(\"Logistic Regression with Balanced Class Weights:\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the step-by-step notebook code for training Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Balanced Class Weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      3574\n",
      "           1       0.02      1.00      0.03         8\n",
      "\n",
      "    accuracy                           0.87      3582\n",
      "   macro avg       0.51      0.94      0.48      3582\n",
      "weighted avg       1.00      0.87      0.93      3582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize Logistic Regression with balanced class weights\n",
    "log_reg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "y_train_pred = log_reg.predict(x_train_scaled)\n",
    "print(\"Logistic Regression with Balanced Class Weights:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Save the model to a .pkl file\n",
    "with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(log_reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_woe = pd.read_csv(\"../data/processed/x_train_woe.csv\")\n",
    "y_train_proxy = pd.read_csv(\"../data/processed/y_train_proxy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_proxy.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_woe shape: (3582, 9)\n",
      "y_train_proxy shape: (3582, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train_woe shape: {x_train_woe.shape}\")\n",
    "print(f\"y_train_proxy shape: {y_train_proxy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_woe = x_train_woe.loc[x_train_woe.index.isin(y_train_proxy.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned shapes: x_train_woe = (3582, 9), y_train_proxy = (3582, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Aligned shapes: x_train_woe = {x_train_woe.shape}, y_train_proxy = {y_train_proxy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CustomerId', 'Label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(y_train_proxy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00       717\n",
      "   macro avg       0.50      0.50      0.50       717\n",
      "weighted avg       0.99      1.00      1.00       717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neba\\Documents\\credit-scoring-project\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\neba\\Documents\\credit-scoring-project\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\neba\\Documents\\credit-scoring-project\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Extract the target column 'Label' from y_train_proxy\n",
    "y_train = y_train_proxy['Label']\n",
    "\n",
    "# Split Data into Training and Validation Sets\n",
    "x_train, x_val, y_train_split, y_val = train_test_split(\n",
    "    x_train_woe, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(x_train, y_train_split)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_val_pred = dt_model.predict(x_val)\n",
    "print(\"Classification Report for Decision Tree:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Decision Tree (with Class Weights):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00       717\n",
      "   macro avg       0.50      0.50      0.50       717\n",
      "weighted avg       0.99      1.00      1.00       717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Classifier with class weights\n",
    "dt_model_weighted = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "dt_model_weighted.fit(x_train, y_train_split)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_val_pred_weighted = dt_model_weighted.predict(x_val)\n",
    "print(\"Classification Report for Decision Tree (with Class Weights):\")\n",
    "print(classification_report(y_val, y_val_pred_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score: 0.9947643979057592\n",
      "Classification Report for Best Decision Tree (with GridSearchCV):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00       717\n",
      "   macro avg       0.50      0.50      0.50       717\n",
      "weighted avg       0.99      1.00      1.00       717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train_split)\n",
    "\n",
    "# Best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model from GridSearch\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "y_val_pred_best = best_dt_model.predict(x_val)\n",
    "print(\"Classification Report for Best Decision Tree (with GridSearchCV):\")\n",
    "print(classification_report(y_val, y_val_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, matthews_corrcoef, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score: 0.9947643979057592\n",
      "Classification Report for Best Decision Tree (with GridSearchCV):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00       717\n",
      "   macro avg       0.50      0.50      0.50       717\n",
      "weighted avg       0.99      1.00      1.00       717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train_split)\n",
    "\n",
    "# Best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model from GridSearch\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "y_val_pred_best = best_dt_model.predict(x_val)\n",
    "print(\"Classification Report for Best Decision Tree (with GridSearchCV):\")\n",
    "print(classification_report(y_val, y_val_pred_best))\n",
    "\n",
    "# Save the best model from GridSearchCV\n",
    "with open('best_decision_tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_dt_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
